{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2a3ff8f-593e-40ed-bbd0-e0adfec7899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071f09a-bfd2-4b7c-8c5b-4ebaefd7b555",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7357211-e300-4271-9c9e-1f5508e76b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/EuroSAT_RGB\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "NUM_CLASSES = 10\n",
    "IMG_SIZE = 64\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6b7c1da-1872-4c28-b154-189aab50fd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirillkapustin/miniconda3/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=[0.3444, 0.3809, 0.4082], std=[0.1459, 0.1132, 0.1137])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a732907-4807-4073-b5f8-8fece429c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.ImageFolder(DATA_DIR, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffb6258c-d921-4f39-9e08-bb567e0e942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 27000\n",
       "    Root location: ../data/EuroSAT_RGB\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "                 Resize(size=[64, 64], interpolation=InterpolationMode.BILINEAR, antialias=True)\n",
       "                 ToTensor()\n",
       "                 Normalize(mean=[0.3444, 0.3809, 0.4082], std=[0.1459, 0.1132, 0.1137], inplace=False)\n",
       "           )"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "252b5a7c-1357-4f6a-b385-8122be17f3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21600, 5400)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8 * len(ds))\n",
    "valid_size = len(ds) - train_size\n",
    "train_size, valid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38d18e28-493b-4af2-a2ce-bf2e4117ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = random_split(ds, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "328021c8-bc8a-4212-89df-e58a2176c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d7ef5-d3a9-4bca-b6f3-e2f452a52d33",
   "metadata": {},
   "source": [
    "### Train Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76ea30e6-8b5c-4783-a518-6f17e73f090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09e75131-a228-493a-a34f-738fda619d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(os.cpu_count()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "369b14c6-c1a8-49ee-b94a-9529a4eda24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95dcf8e6-7d16-4562-bda4-8107018d25a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee04f079-52a1-49b3-8984-0dc84aa80a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e098fb-040c-403b-b737-f04c3948a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for imgs, labels in train_dl:\n",
    "        imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(imgs)\n",
    "        loss = loss_func(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{EPOCHS}] Train Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78024f-db24-403c-a194-67eeeb00be93",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d8005-7c46-4475-9a52-8ef5f942c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    acc = correct / total\n",
    "    print(f\"Validation Accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2353f34c-1e53-43fb-8f3b-85a6a72dfb27",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab42cc9-a010-4f6f-a26a-9d665ca95fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"model/resnet18_eurosat.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23704e02-3021-4bed-8d3d-327779c674f4",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9e9cc-8c51-4b6f-91fc-9c396fc78865",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.3444, 0.3809, 0.4082], std=[0.1459, 0.1132, 0.1137])\n",
    "])\n",
    "\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)  # [B, C, H, W]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probs = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    \n",
    "    predicted_class = classes[probs.argmax().item()]\n",
    "    confidence = probs.max().item()\n",
    "\n",
    "    return predicted_class, round(confidence, 3), probs.cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
